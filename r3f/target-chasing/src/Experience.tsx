import { useFrame } from "@react-three/fiber";
import { RigidBody, RapierRigidBody } from "@react-three/rapier";
import { useRef, forwardRef, useImperativeHandle } from "react";
import { Vector3 } from "three";
import { DQNAgent } from "@ignitionai/backend-tfjs";
import { IgnitionEnv } from "@ignitionai/core";
import React from "react";
import { useTrainingStore } from "./store/trainingStore";

const MOVEMENT_SPEED = 100;

// Constantes pour les limites du plateau
const PLATEAU_LIMITS = {
  minX: -500, // Moiti√© de la largeur du ground (1000/2)
  maxX: 500,  // Moiti√© de la largeur du ground (1000/2)
  minY: -1,   // L√©g√®rement en-dessous du ground
  maxY: 100,  // Hauteur maximale
  minZ: -500, // Moiti√© de la profondeur du ground (1000/2)
  maxZ: 500   // Moiti√© de la profondeur du ground (1000/2)
};

// Fonction pour g√©n√©rer une position al√©atoire pour la cible
function getRandomTargetPosition(): [number, number, number] {
  // Limiter la zone o√π la cible peut appara√Ætre pour √©viter qu'elle soit trop pr√®s des bords
  const margin = 100; // Marge par rapport aux bords
  const x = Math.random() * (PLATEAU_LIMITS.maxX - PLATEAU_LIMITS.minX - 2 * margin) + PLATEAU_LIMITS.minX + margin;
  const y = 10; // Hauteur fixe pour la cible
  const z = Math.random() * (PLATEAU_LIMITS.maxZ - PLATEAU_LIMITS.minZ - 2 * margin) + PLATEAU_LIMITS.minZ + margin;
  
  return [x, y, z];
}

function Ground() {
  return (
    <RigidBody type="fixed">
      <mesh receiveShadow position={[0, -0.5, 0]}>
        <boxGeometry args={[1000, 1, 1000]} />
        <meshStandardMaterial color="gray" />
      </mesh>
    </RigidBody>
  );
}

function Cible({cibleRef, position}: {cibleRef: React.RefObject<RapierRigidBody | null>, position: [number, number, number]}) {
  // Utiliser la position fournie en prop
  return (
    <RigidBody  
      ref={cibleRef}
      type="kinematicPosition" 
      position={position} 
      shape="cuboid"
      linearDamping={0.5}
      mass={1}
      friction={0}
      lockRotations
      sensor // Ajouter cette propri√©t√© pour que la cible soit un capteur et non un objet solide
    >
      <mesh castShadow>
        <boxGeometry args={[20, 20, 20]} />
        <meshStandardMaterial color="red" />
      </mesh>
    </RigidBody>
  );
}

const Agent = forwardRef(function Agent({targetPosition}: {targetPosition: [number, number, number]}, ref) { 
  // R√©f√©rences et √©tats
  const bodyRef = useRef<RapierRigidBody>(null);
  const initialPosition: [number, number, number] = [100, 10, 100]; // Position de d√©part √©loign√©e
  
  // Utiliser le store Zustand au lieu des useState - ne garder que ce qui est n√©cessaire
  const { 
    isTraining, setIsTraining,
    episodeCount, setEpisodeCount,
    setReward,
    bestReward, setBestReward,
    episodeSteps, setEpisodeSteps,
    setReachedTarget,
    episodeTime, setEpisodeTime,
    episodeStartTime, setEpisodeStartTime,
    setSuccessCount,
    difficulty, setDifficulty,
    setLastAction,
  } = useTrainingStore();
  
  // R√©f√©rence √† l'environnement (initialis√© une seule fois)
  const envRef = useRef<IgnitionEnv | null>(null);
  
  // R√©f√©rence √† la derni√®re distance pour calculer la progression
  const lastDistance = useRef(Infinity);
  
  // Calculer la position initiale en fonction de la difficult√©
  const getStartingPosition = (): [number, number, number] => {
    // Si difficult√© = 0, on commence tr√®s proche de la cible
    if (difficulty === 0) {
      return [targetPosition[0] + 30, targetPosition[1], targetPosition[2] + 30];
    }
    // Si difficult√© = 1, on commence √† distance moyenne
    else if (difficulty === 1) {
      return [targetPosition[0] + 60, targetPosition[1], targetPosition[2] + 60];
    }
    // Sinon, on commence √† la position normale
    return initialPosition;
  };
  
  // Cr√©er l'environnement s'il n'existe pas encore
  if (!envRef.current) {
    console.log("üîÑ Initialisation de l'environnement d'apprentissage");
    
    const dqnAgent = new DQNAgent({
      actionSize: 4,
      inputSize: 9,
      epsilon: 0.9,            // moins haut
      epsilonDecay: 0.97,      // decay plus rapide
      minEpsilon: 0.05,
      gamma: 0.99,
      lr: 0.001,
      batchSize: 128,          // batch plus large
      hiddenLayers: [64, 64],
      memorySize: 100000,
      targetUpdateFrequency: 200,
    });
    
    envRef.current = new IgnitionEnv({
      agent: dqnAgent,
      getObservation: () => {
        const pos = bodyRef.current?.translation() || { x: 0, y: 0, z: 0 };
        
        // Direction vers la cible (vecteur normalis√©)
        const dirX = targetPosition[0] - pos.x;
        const dirY = targetPosition[1] - pos.y;
        const dirZ = targetPosition[2] - pos.z;
        const dirMagnitude = Math.sqrt(dirX*dirX + dirY*dirY + dirZ*dirZ);
        
        // Normaliser les distances aux limites
        const distToMinX = (pos.x - PLATEAU_LIMITS.minX) / 1000;
        const distToMaxX = (PLATEAU_LIMITS.maxX - pos.x) / 1000;
        const distToMinZ = (pos.z - PLATEAU_LIMITS.minZ) / 1000;
        const distToMaxZ = (PLATEAU_LIMITS.maxZ - pos.z) / 1000;
        const distToGround = (pos.y - PLATEAU_LIMITS.minY) / 100;
        
        return [
          dirX / (dirMagnitude + 0.001),  // Direction normalis√©e X vers la cible
          dirY / (dirMagnitude + 0.001),  // Direction normalis√©e Y vers la cible 
          dirZ / (dirMagnitude + 0.001),  // Direction normalis√©e Z vers la cible
          dirMagnitude / 1000,            // Distance normalis√©e
          distToMinX,                     // Distance √† la limite X minimale
          distToMaxX,                     // Distance √† la limite X maximale
          distToGround,                   // Distance au sol
          distToMinZ,                     // Distance √† la limite Z minimale
          distToMaxZ,                     // Distance √† la limite Z maximale
        ];
      },
      applyAction: (action: number | number[]) => {
        // Incr√©menter le compteur d'√©tapes √† chaque action
        setEpisodeSteps(prev => prev + 1);
        
        // Tester si le Rigidbody existe
        if (!bodyRef.current) {
          console.error("‚ùå bodyRef.current est null!");
          return;
        }
        
        // V√©rifier l'√©tat actuel de l'agent
        const pos = bodyRef.current.translation();
        const shouldRandomize = episodeSteps < 20 && Math.random() < 0.5;
        
        if (Array.isArray(action)) {
          bodyRef.current.setLinvel(new Vector3(
            action[0] * MOVEMENT_SPEED, 
            action[1] * MOVEMENT_SPEED, 
            action[2] * MOVEMENT_SPEED
          ), true);
        } else {
          let finalAction = action;
          
          // Parfois, choisir une action al√©atoire au d√©but
          if (shouldRandomize) {
            finalAction = Math.floor(Math.random() * 4);
            console.log(`üé≤ Action randomis√©e: ${finalAction}`);
          }
          
          setLastAction(finalAction);
          
          // TR√àS grandes forces pour s'assurer que l'agent bouge
          const velocity = MOVEMENT_SPEED * 5;
          
          // Utiliser setLinvel pour un mouvement direct plut√¥t que des impulsions
          switch(finalAction) {
            case 0: // Gauche
              console.log("‚¨ÖÔ∏è Mouvement: GAUCHE");
              bodyRef.current.setLinvel(new Vector3(-velocity, 0, 0), true); 
              break;
            case 1: // Droite
              console.log("‚û°Ô∏è Mouvement: DROITE");
              bodyRef.current.setLinvel(new Vector3(velocity, 0, 0), true); 
              break; 
            case 2: // Avant (vers la cible sur Z)
              console.log("‚¨ÜÔ∏è Mouvement: AVANT");
              bodyRef.current.setLinvel(new Vector3(0, 0, -velocity), true); 
              break;
            case 3: // Arri√®re
              console.log("‚¨áÔ∏è Mouvement: ARRI√àRE");
              bodyRef.current.setLinvel(new Vector3(0, 0, velocity), true); 
              break;
            default:
              bodyRef.current.setLinvel(new Vector3(0, 0, 0), true);
          }
          
          // Forcer les logs √† chaque action pour d√©bogage
          console.log(`Action: ${finalAction}, Position: [${pos.x.toFixed(2)}, ${pos.y.toFixed(2)}, ${pos.z.toFixed(2)}]`);
        }
      },
      computeReward: () => {
        const pos = bodyRef.current?.translation() || { x: 0, y: 0, z: 0 };
        const distance = Math.sqrt(
          Math.pow(pos.x - targetPosition[0], 2) +
          Math.pow(pos.y - targetPosition[1], 2) +
          Math.pow(pos.z - targetPosition[2], 2)
        );
        
        // Calculer la r√©compense
        let calculatedReward = 0;
        
        // V√©rifier si l'agent est sorti du plateau - forte p√©nalit√©
        if (pos.x < PLATEAU_LIMITS.minX || pos.x > PLATEAU_LIMITS.maxX ||
            pos.y < PLATEAU_LIMITS.minY || pos.y > PLATEAU_LIMITS.maxY ||
            pos.z < PLATEAU_LIMITS.minZ || pos.z > PLATEAU_LIMITS.maxZ) {
          return -100; // P√©nalit√© pour √™tre sorti
        }
        
        // V√©rifier si l'agent a atteint la cible - √©norme r√©compense
        if (distance < 25) {
          console.log(`üèÜ TOUCH√â! Distance = ${distance.toFixed(2)}`);
          setReachedTarget(true);
          // Incr√©menter imm√©diatement le succ√®s pour s'assurer qu'il est compt√©
          setSuccessCount(prev => {
            console.log(`‚úÖ Succ√®s incr√©ment√©: ${prev} -> ${prev + 1}`);
            // Augmenter la difficult√© apr√®s plusieurs succ√®s
            if ((prev + 1) % 3 === 0) {
              setDifficulty(prevDiff => Math.min(prevDiff + 1, 2));
              console.log(`üîº Difficult√© augment√©e √† ${Math.min((prev + 1) % 3 + 1, 3)}`);
            }
            return prev + 1;
          });
          return 100; // R√©compense tr√®s √©lev√©e pour atteindre la cible
        }
        
        const proximityReward = Math.max(0, 2 * (1 - distance / 200)); // au lieu de 1x
        calculatedReward = proximityReward;
        
        // R√©compense additionnelle si l'agent se rapproche de la cible
        const distanceDelta = lastDistance.current - distance;
        if (distanceDelta > 0) {
          // Bonus pour se rapprocher
          calculatedReward += 0.2; 
        } else {
          // P√©nalit√© pour s'√©loigner
          calculatedReward -= 0.1;
        }
        
        // Mettre √† jour la derni√®re distance
        lastDistance.current = distance;
        
        // Log de d√©bogage
        if (episodeSteps % 60 === 0) {
          console.log(`Distance: ${distance.toFixed(2)}, R√©compense: ${calculatedReward.toFixed(2)}`);
        }
        
        // Mettre √† jour les stats pour l'UI
        setReward(calculatedReward);
        if (calculatedReward > bestReward) {
          setBestReward(calculatedReward);
        }
        
        return calculatedReward;
      },
      isDone: () => {
        // Un √©pisode se termine si:
        // 1. L'agent a atteint la cible
        // 2. Plus de 20 secondes se sont √©coul√©es
        // 3. L'agent est sorti du plateau (Ground)
        
        // V√©rification imm√©diate si l'agent est sorti du plateau
        const pos = bodyRef.current?.translation() || { x: 0, y: 0, z: 0 };
        
        // V√©rifier si l'agent est sorti du plateau
        if (pos.x < PLATEAU_LIMITS.minX || pos.x > PLATEAU_LIMITS.maxX ||
            pos.y < PLATEAU_LIMITS.minY || // V√©rifie s'il est tomb√© sous le ground
            pos.z < PLATEAU_LIMITS.minZ || pos.z > PLATEAU_LIMITS.maxZ) {
          
          console.log(`L'agent est sorti du plateau: [${pos.x.toFixed(2)}, ${pos.y.toFixed(2)}, ${pos.z.toFixed(2)}]`);
          return true; // Terminer l'√©pisode imm√©diatement
        }
        
        // V√©rifier si l'agent a atteint la cible
        const distance = Math.sqrt(
          Math.pow(pos.x - targetPosition[0], 2) +
          Math.pow(pos.y - targetPosition[1], 2) +
          Math.pow(pos.z - targetPosition[2], 2)
        );
        
        if (distance < 25) {
          console.log(`üéØ SUCC√àS! L'agent a atteint la cible!`);
          return true;
        }
        
        // V√©rifier le temps √©coul√© (limite √† 20 secondes)
        if (episodeTime >= 20) {
          console.log(`‚è±Ô∏è √âpisode termin√© apr√®s ${episodeTime.toFixed(1)} secondes`);
          return true;
        }
        
        return false;
      },
      onReset: () => {
        // R√©initialiser la position de l'agent selon la difficult√© actuelle
        const startPos = getStartingPosition();
        bodyRef.current?.setLinvel(new Vector3(0, 0, 0), true);
        bodyRef.current?.setTranslation(
          new Vector3(startPos[0], startPos[1], startPos[2]), 
          true
        );
        
        // Ne PAS mettre √† jour le nombre de succ√®s ici, car c'est d√©j√† fait dans computeReward
        
        // R√©initialiser les compteurs
        setEpisodeSteps(0);
        setReachedTarget(false);
        setEpisodeCount(prev => prev + 1);
        setEpisodeTime(0);
        setEpisodeStartTime(Date.now());
        lastDistance.current = Infinity;
        
        // G√©n√©rer une nouvelle position pour la cible √† chaque √©pisode
        const { setTargetPosition } = useTrainingStore.getState();
        setTargetPosition(getRandomTargetPosition());
        
        console.log(`√âpisode ${episodeCount} termin√©.`);
      },
      stepIntervalMs: 1000 / 60, // 60fps
    });
  }
  
  // Test de mouvement p√©riodique pour v√©rifier si l'agent peut bouger
  useFrame(({clock}) => {
    // V√©rifier toutes les 5 secondes si l'agent ne bouge pas
    if (isTraining && clock.getElapsedTime() % 5 < 0.1 && bodyRef.current) {
      const pos = bodyRef.current.translation();
      const vel = bodyRef.current.linvel();
      console.log(`‚è±Ô∏è Position actuelle: [${pos.x.toFixed(2)}, ${pos.y.toFixed(2)}, ${pos.z.toFixed(2)}]`);
      console.log(`üöÄ Vitesse actuelle: [${vel.x.toFixed(2)}, ${vel.y.toFixed(2)}, ${vel.z.toFixed(2)}]`);
      
      // Si la vitesse est presque nulle, tenter un mouvement de test
      if (Math.abs(vel.x) < 0.1 && Math.abs(vel.z) < 0.1) {
        console.log("üîÑ Test de mouvement (agent coinc√©?)");
        const testImpulse = MOVEMENT_SPEED * 10;
        bodyRef.current.applyImpulse(new Vector3(0, 0, -testImpulse), true);
      }
    }
  });
  
  // Boucle principale, mettre √† jour le temps de l'√©pisode
  useFrame(() => {
    if (isTraining && envRef.current) {
      const { isTrainingInProgress, setIsTrainingInProgress } = useTrainingStore.getState();
      
      // V√©rifier si un entra√Ænement est d√©j√† en cours
      if (!isTrainingInProgress) {
        // Marquer l'entra√Ænement comme en cours
        setIsTrainingInProgress(true);
        
        // Ex√©cuter step() de mani√®re asynchrone
        Promise.resolve().then(async () => {
          try {
            // Appeler step() de mani√®re s√©curis√©e
            await envRef.current?.step();
          } catch (error) {
            console.error("Erreur pendant l'entra√Ænement:", error);
          } finally {
            // Marquer l'entra√Ænement comme termin√©
            setIsTrainingInProgress(false);
          }
        });
      }
      
      // Mettre √† jour le temps √©coul√© de l'√©pisode
      const currentTime = Date.now();
      const elapsedSeconds = (currentTime - episodeStartTime) / 1000;
      setEpisodeTime(elapsedSeconds);
      
      // Forcer l'arr√™t de l'√©pisode apr√®s 20 secondes
      if (elapsedSeconds > 20 && envRef.current) {
        console.log("‚ö†Ô∏è Arr√™t forc√© de l'√©pisode apr√®s 20 secondes!");
        envRef.current.reset();
      }
    }
  });
  
  // Fonctions de contr√¥le
  const startTraining = () => {
    setIsTraining(true);
    if (envRef.current) {
      envRef.current.start();
    }
  };
  
  const stopTraining = () => {
    setIsTraining(false);
    if (envRef.current) {
      envRef.current.stop();
    }
  };
  
  const resetEnvironment = () => {
    if (envRef.current) {
      // G√©n√©rer une nouvelle position pour la cible
      const { setTargetPosition } = useTrainingStore.getState();
      setTargetPosition(getRandomTargetPosition());
      
      envRef.current.reset();
    }
  };
  
  // Exposer les m√©thodes via useImperativeHandle
  useImperativeHandle(ref, () => ({
    startTraining,
    stopTraining,
    resetEnvironment,
    // Ajouter une m√©thode pour obtenir la position actuelle de l'agent
    getAgentPosition: () => {
      if (bodyRef.current) {
        return bodyRef.current.translation();
      }
      return { x: 0, y: 0, z: 0 };
    },
    // Ajouter une m√©thode pour g√©rer quand l'agent atteint la cible
    handleTargetReached: () => {
      // Incr√©menter le compteur de succ√®s
      setSuccessCount(prev => {
        console.log(`‚úÖ Succ√®s incr√©ment√©: ${prev} -> ${prev + 1}`);
        // Augmenter la difficult√© apr√®s plusieurs succ√®s
        if ((prev + 1) % 3 === 0) {
          setDifficulty(prevDiff => Math.min(prevDiff + 1, 2));
          console.log(`üîº Difficult√© augment√©e √† ${Math.min((prev + 1) % 3 + 1, 3)}`);
        }
        return prev + 1;
      });
      
      // R√©initialiser l'environnement
      if (envRef.current) {
        // G√©n√©rer une nouvelle position pour la cible
        const { setTargetPosition } = useTrainingStore.getState();
        setTargetPosition(getRandomTargetPosition());
        
        // R√©initialiser l'agent
        envRef.current.reset();
      }
    }
  }));
  
  return (
    <>
      <RigidBody 
        ref={bodyRef}
        position={getStartingPosition()}
        type="dynamic" 
        shape="cuboid"
        linearDamping={0.1}  // R√©duire l'amortissement pour que l'agent puisse bouger plus facilement
        mass={0.5}           // R√©duire la masse pour faciliter le mouvement 
        friction={0}
        lockRotations
      >
        <mesh castShadow>
          <boxGeometry args={[20, 20, 20]} />
          <meshStandardMaterial color="blue" />
        </mesh>
      </RigidBody>
    </>
  );
});

const Experience = forwardRef(function Experience(_, ref) {
  const cibleRef = useRef<RapierRigidBody | null>(null);
  const { targetPosition, setTargetPosition } = useTrainingStore();
  const agentRef = useRef<any>(null);
  
  // R√©f√©rence pour la d√©tection de collision stable
  const collisionDetectionRef = useRef({
    consecutiveCollisions: 0,
    lastCollisionTime: 0,
    collisionInProgress: false
  });
  
  // Exposer les m√©thodes de contr√¥le via useImperativeHandle
  useImperativeHandle(ref, () => ({
    startTraining: () => {
      if (agentRef.current) {
        agentRef.current.startTraining();
      }
    },
    stopTraining: () => {
      if (agentRef.current) {
        agentRef.current.stopTraining();
      }
    },
    resetEnvironment: () => {
      if (agentRef.current) {
        agentRef.current.resetEnvironment();
      }
    }
  }));
  
  // Initialiser la position de la cible au premier rendu
  React.useEffect(() => {
    setTargetPosition(getRandomTargetPosition());
  }, [setTargetPosition]);
  
  // Ajouter un gestionnaire de collision pour d√©tecter quand l'agent touche la cible
  React.useEffect(() => {
    // Fonction pour v√©rifier les collisions manuellement
    const checkCollisions = () => {
      if (!agentRef.current || !cibleRef.current) return;
      
      // Obtenir les positions
      const agentPos = agentRef.current.getAgentPosition();
      const ciblePos = cibleRef.current.translation();
      
      // Calculer la distance
      const distance = Math.sqrt(
        Math.pow(agentPos.x - ciblePos.x, 2) +
        Math.pow(agentPos.y - ciblePos.y, 2) +
        Math.pow(agentPos.z - ciblePos.z, 2)
      );
      
      // Ajuster le seuil de collision en fonction de la taille r√©elle des objets
      // La taille de l'agent et de la cible est de 20 unit√©s chacun, donc une distance de 20 unit√©s
      // signifie que les bords se touchent. Utilisons une valeur l√©g√®rement plus petite pour √™tre s√ªr.
      const collisionThreshold = 22; // Somme des rayons (10+10) + une petite marge d'erreur (2)
      
      // Si la distance est inf√©rieure au seuil, il y a potentiellement une collision
      if (distance < collisionThreshold) {
        // Incr√©menter le compteur de collisions cons√©cutives
        collisionDetectionRef.current.consecutiveCollisions++;
        collisionDetectionRef.current.lastCollisionTime = Date.now();
        
        // Si nous avons d√©tect√© plusieurs collisions cons√©cutives et qu'aucune collision n'est en cours
        if (collisionDetectionRef.current.consecutiveCollisions >= 2 && !collisionDetectionRef.current.collisionInProgress) {
          console.log(`üéØ Collision confirm√©e! Distance: ${distance.toFixed(2)}`);
          // Marquer qu'une collision est en cours pour √©viter les d√©clenchements multiples
          collisionDetectionRef.current.collisionInProgress = true;
          
          // D√©clencher manuellement la r√©compense et la r√©initialisation
          if (agentRef.current) {
            agentRef.current.handleTargetReached();
          }
          
          // R√©initialiser le compteur apr√®s un certain d√©lai
          setTimeout(() => {
            collisionDetectionRef.current.consecutiveCollisions = 0;
            collisionDetectionRef.current.collisionInProgress = false;
          }, 1000);
        }
      } else {
        // Si la distance est sup√©rieure au seuil, r√©initialiser le compteur
        // mais seulement si un certain temps s'est √©coul√© depuis la derni√®re collision
        const timeSinceLastCollision = Date.now() - collisionDetectionRef.current.lastCollisionTime;
        if (timeSinceLastCollision > 300) {
          collisionDetectionRef.current.consecutiveCollisions = 0;
        }
      }
    };
    
    // R√©duire la fr√©quence des v√©rifications pour √©viter les faux positifs
    const interval = setInterval(checkCollisions, 200);
    
    return () => {
      clearInterval(interval);
    };
  }, []);
  
  useFrame(() => {
    if (cibleRef.current) {
      // Mettre √† jour la position du RigidBody de la cible
      cibleRef.current.setTranslation(
        new Vector3(targetPosition[0], targetPosition[1], targetPosition[2]),
        true
      );
      
      // Mettre √† jour la position dans le store (pour l'agent)
      const pos = cibleRef.current.translation();
      if (pos.x !== targetPosition[0] || pos.y !== targetPosition[1] || pos.z !== targetPosition[2]) {
        setTargetPosition([pos.x, pos.y, pos.z]);
      }
    }
  });

  return (
    <>
      <ambientLight intensity={0.3} />
      <directionalLight
        position={[10, 10, 10]}
        intensity={3}
        castShadow
        shadow-mapSize={[1024, 1024]}
      />
      <Agent ref={agentRef} targetPosition={targetPosition} />
      <Cible cibleRef={cibleRef} position={targetPosition} />
      <Ground />
    </>
  );
});

export default Experience;