# ğŸ§­ IgnitionAI - Project Roadmap

This document outlines the phased development of **IgnitionAI** â€” a modular, browser-friendly framework for intelligent agent simulation and reinforcement learning.

---

## âœ… Phase 1 â€” Core Logic (MVP)

> âš™ï¸ Goal: Run agent-environment logic headlessly (no UI)

âœ… Roadmap for "RL algo first"
Phase A â€” @ignitionai/backend-tfjs only
Implementing classic algorithms with TensorFlow.js

1. ğŸ” Q-learning (tabular) â€“ minimalist JS version
without neural networks
âœ… Implemented Q-Table agent with state/action lookup
âœ… Added tests for basic functionality

2. ğŸ§  DQN â€“ Deep Q-Network
âœ… Implemented MLP simple input â†’ hidden â†’ output
âœ… Added replay buffer with experience sampling
âœ… Implemented target network with periodic updates
âœ… Added epsilon-greedy exploration/exploitation
âœ… Loss function based on TD error
âœ… Unit tests with training validation

3. ğŸ§˜â€â™‚ï¸ PPO â€“ Policy Gradient
âœ… Created initial PPO agent skeleton
- [ ] Implement Actor-Critic model
- [ ] Implement episode-based training
- [ ] Add policy and value loss functions

---

## ğŸš€ Phase 1.5 â€” Backend Infrastructure

> ğŸ§° Goal: Create robust, multi-environment backend support

âœ… Created modular monorepo structure
âœ… Implemented robust backend selection system
âœ… Added support for all major TensorFlow.js backends:
  - WebGPU (experimental)
  - WebGL
  - CPU
  - WASM
âœ… Added helper utilities for backend detection and info
âœ… Comprehensive unit tests and error handling
- [ ] Add model serialization and loading

---

## ğŸŒ Phase 2 â€” R3F Visualisation

> ğŸ® Goal: Make the agent & target visible in a 3D scene

- [ ] `@ignitionai/r3f`: add `AgentMesh`, `TargetMesh`, `useAgent`
- [ ] `@ignitionai/demo-target-chasing`: setup Vite + R3F scene
- [ ] Display step count and reward in the UI

---

## ğŸ¤– Phase 3 â€” TFJS Backend (Training & Inference)

> ğŸ§  Goal: Train and run a model directly in the browser

âœ… `@ignitionai/backend-tfjs`: built simple MLP model with configurable layers
âœ… Implemented `train()` and `predict()` APIs via DQN agent
- [ ] Add model serialization with `save()` and `load()`
- [ ] Create streamlined `Agent` class interface

---

## âš¡ Phase 4 â€” ONNX Runtime Backend (Inference-only)

> âš¡ Goal: Run optimized pre-trained models in production

âœ… Created initial package structure for ONNX backend
- [ ] Implement ONNX Runtime Web integration
- [ ] Add `.onnx` model loading and inference
- [ ] Create `InferenceBackend` wrapper

---

## ğŸ§  Phase 5 â€” Cognitive Agents (LLM & Planning)

> ğŸ“š Goal: Enable agents with memory, reasoning and goals

- [ ] `@ignitionai/backend-langchain`: LLM-powered agent
- [ ] `@ignitionai/backend-vercelai`: edge-deployed AI actions
- [ ] Add simple text environment or RAG-driven simulation

---

## ğŸ Stretch Goals

- [ ] Physics-based environment (BallBalancer, CartPole3D)
- [ ] Multi-agent mode
- [ ] Export agent replay logs
- [ ] Web UI training dashboard
- [ ] OpenHub-like demo launcher

---

Built with â¤ï¸ by Salim (@IgnitionAI)
